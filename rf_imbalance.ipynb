{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "omFIoo4MLQZw"
   },
   "outputs": [],
   "source": [
    "# Import the main packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from prettytable import PrettyTable\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "KIqa1Co2LQZ1",
    "outputId": "38164214-27d6-4258-a07d-8965d440f226"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset and take a quick look\n",
    "\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the response variable for data imbalance\n",
    "\n",
    "count0, count1 = df['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of diabetics in the dataset is only 34.90%\n"
     ]
    }
   ],
   "source": [
    "print(f'The percentage of diabetics in the dataset is only {100*count1/(count0+count1):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZmSf9ELsLQZ4"
   },
   "outputs": [],
   "source": [
    "# Assign the predictor and response variables.\n",
    "\n",
    "# Outcome is the response and all the other columns are the predictors\n",
    "\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix a random_state and split the data into train and validation sets\n",
    "random_state = 22\n",
    "\n",
    "X_train, X_val, y_train,y_val = train_test_split(X,y,train_size = 0.8,random_state =random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7kxrHNda3OB2"
   },
   "outputs": [],
   "source": [
    "# We fix the max_depth variable to 20 for all trees\n",
    "\n",
    "max_depth = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4ZfRvt_04Xr"
   },
   "source": [
    "## Strategy 1 - Vanilla Random Forest\n",
    "\n",
    "- No correction for imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "K17Dfd7dLQZ9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, n_estimators=10, random_state=22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a Random Forest classifier with randon_state as above\n",
    "\n",
    "# Set the maximum depth to be max_depth and use 10 estimators\n",
    "\n",
    "random_forest = RandomForestClassifier(max_depth=max_depth, random_state=random_state, n_estimators=10)\n",
    "\n",
    "# Fit the model on the training set\n",
    "\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make predictions on the validation set \n",
    "\n",
    "predictions = random_forest.predict(X_val)\n",
    "\n",
    "# We also compute two metrics that better represent misclassification of minority classes i.e `f1 score` and `AUC`\n",
    "\n",
    "# compute the f1-score and assign it to variable score1\n",
    "\n",
    "score1 = round(f1_score(predictions,y_val),2)\n",
    "\n",
    "# compute the `auc` and assign it to variable auc1\n",
    "\n",
    "auc1 = round(roc_auc_score(predictions,y_val),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTb4xjjf1M2G"
   },
   "source": [
    "## Strategy 2 - Random Forest with class weighting\n",
    "- Balancing the class imbalance in each bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WoUks9q_MWGM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', max_depth=20,\n",
       "                       n_estimators=10, random_state=22)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again Define a Random Forest classifier with randon_state as above\n",
    "\n",
    "# Set the maximum depth to be max_depth and use 10 estimators\n",
    "\n",
    "random_forest = RandomForestClassifier(max_depth=max_depth, random_state=random_state, n_estimators=10,class_weight='balanced_subsample')\n",
    "\n",
    "# Fit the model on the training set\n",
    "\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "K0FJ-kXT3wFK"
   },
   "outputs": [],
   "source": [
    "# We make predictions on the validation set \n",
    "\n",
    "predictions = random_forest.predict(X_val)\n",
    "\n",
    "# Again we also compute two metrics that better represent misclassification of minority classes i.e `f1 score` and `AUC`\n",
    "\n",
    "# compute the f1-score and assign it to variable score2\n",
    "\n",
    "score2 = round(f1_score(predictions,y_val),2)\n",
    "\n",
    "# compute the `auc` and assign it to variable auc2\n",
    "\n",
    "auc2 = round(roc_auc_score(predictions,y_val),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy 3 - Balanced Random Forest with SMOTE \n",
    "\n",
    "- Using the **imblearn** `BalancedRandomForestClassifier()` \n",
    "- Read more about this implementation [here](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.ensemble.BalancedRandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BalancedRandomForestClassifier(class_weight='balanced_subsample', max_depth=20,\n",
       "                               n_estimators=10, random_state=22)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This define, define a `Balanced Random Forest Classifier` which is superior to sklearn's implementation\n",
    "\n",
    "random_forest = BalancedRandomForestClassifier(max_depth=max_depth, random_state=random_state, n_estimators=10, class_weight='balanced_subsample')\n",
    "\n",
    "# Fit the model on the entire data\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make predictions on the validation set \n",
    "\n",
    "predictions = random_forest.predict(X_val)\n",
    "\n",
    "# compute the f1-score and assign it to variable score3\n",
    "\n",
    "score3 = round(f1_score(predictions,y_val),2)\n",
    "\n",
    "# compute the `auc` and assign it to variable auc3\n",
    "\n",
    "auc3 = round(roc_auc_score(predictions,y_val),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+----------+-----------+\n",
      "|                 Strategy                | F1 Score | AUC score |\n",
      "+-----------------------------------------+----------+-----------+\n",
      "| Random Forest - No imbalance correction |   0.44   |    0.68   |\n",
      "|   Random Forest - balanced_subsamples   |   0.51   |    0.7    |\n",
      "|     Random Forest - SMOTE balancing     |   0.63   |    0.71   |\n",
      "+-----------------------------------------+----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Finally, we compare the results from the three implementations above\n",
    "\n",
    "pt = PrettyTable()\n",
    "pt.field_names = [\"Strategy\",\"F1 Score\",\"AUC score\"]\n",
    "pt.add_row([\"Random Forest - No imbalance correction\",score1,auc1])\n",
    "pt.add_row([\"Random Forest - balanced_subsamples\",score2,auc2])\n",
    "pt.add_row([\"Random Forest - SMOTE balancing\",score3,auc3])\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mindchow üç≤\n",
    "\n",
    "- How is the imblearn implementation different from sklearn?\n",
    "- How is it giving you superior results?\n",
    "\n",
    "Read more about **imblearn**'s implementation of `BalancedRandomForestClassifier` and try tweaking it to get a higher f1 and AUC score.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "feature_importance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
